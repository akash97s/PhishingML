{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import joblib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.model_selection\n",
    "import sklearn.metrics\n",
    "import sklearn.neural_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def confusion_matrix(y_test, predictions):\n",
    "\n",
    "    cm=confusion_matrix(y_test,predictions)\n",
    "# sns.heatmap(cm,annot=True)\n",
    "# print(cm)\n",
    "    conf_matrix = confusion_matrix(y_true=y_test, predictions=predictions)\n",
    "#\n",
    "# Print the confusion matrix using Matplotlib\n",
    "#\n",
    "    fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "    ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        for j in range(conf_matrix.shape[1]):\n",
    "            ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    " \n",
    "    plt.xlabel('Predictions', fontsize=18)\n",
    "    plt.ylabel('Actuals', fontsize=18)\n",
    "    plt.title('Confusion Matrix', fontsize=18)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate\n",
    "def train_and_evaluate(X_train, Y_train, X_test, Y_test):\n",
    "    \n",
    "    # Create a model\n",
    "#     model = sklearn.neural_network.MLPClassifier(activation='relu', solver='adam', \n",
    "#                                                  alpha=0.0001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001, power_t=0.5, \n",
    "#                                                  max_iter=1000, shuffle=True, random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "#                                                  nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, \n",
    "#                                                  n_iter_no_change=10)\n",
    "    \n",
    "    model = sklearn.neural_network.MLPClassifier()\n",
    "#     model = sklearn.neural_network.MLPClassifier(hidden_layer_sizes=(100,100,100), max_iter=100, alpha=0.0001,\n",
    "#                                                      solver='sgd', verbose=10,  random_state=21,tol=0.000000001)\n",
    "    # Train the model on the whole data set\n",
    "    model.fit(X_train, Y_train)\n",
    "    # Save the model (Make sure that the folder exists)\n",
    "    joblib.dump(model, 'mlp_classifier.jbl')\n",
    "    # Evaluate on training data\n",
    "    print('\\n-- Training data --')\n",
    "    predictions = model.predict(X_train)\n",
    "    accuracy = sklearn.metrics.accuracy_score(Y_train, predictions)\n",
    "    print('Accuracy: {0:.2f}'.format(accuracy * 100.0))\n",
    "    print('Classification Report:')\n",
    "    print(sklearn.metrics.classification_report(Y_train, predictions))\n",
    "    print('Confusion Matrix:')\n",
    "    print(sklearn.metrics.confusion_matrix(Y_train, predictions))\n",
    "    print('')\n",
    "    \n",
    "    # Evaluate on test data\n",
    "    print('\\n---- Test data ----')\n",
    "    predictions = model.predict(X_test)\n",
    "    accuracy = sklearn.metrics.accuracy_score(Y_test, predictions)\n",
    "    print('Accuracy: {0:.2f}'.format(accuracy * 100.0))\n",
    "    print('Classification Report:')\n",
    "    print(sklearn.metrics.classification_report(Y_test, predictions))\n",
    "    print('Confusion Matrix:')\n",
    "    confusion_matrix(Y_test, predictions)\n",
    "#     print(sklearn.metrics.confusion_matrix(Y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classifier(X, Y):\n",
    "    \n",
    "    # Load the model\n",
    "    model = joblib.load('mlp_classifier.jbl')\n",
    "    # Calculate\n",
    "    h = 0.02\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    \n",
    "    # Make predictions\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    # Plot diagram\n",
    "    fig = plt.figure(figsize = (12, 8))\n",
    "    plt.contourf(xx, yy, Z, cmap='ocean', alpha=0.25)\n",
    "    plt.contour(xx, yy, Z, colors='w', linewidths=0.4)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=Y, s=40, cmap='Spectral')\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.savefig('mlp_classifier.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Load data set (includes header values)\n",
    "    df = pandas.read_csv('combined_dataset.csv')\n",
    "    # Slice data set in data and labels (2D-array)\n",
    "    inputs = df.drop(['label', 'domain'], axis=1)\n",
    "    outputs = df.label\n",
    "    # Split data set in train and test (use random state to get the same split every time, and stratify to keep balance)\n",
    "            \n",
    "    x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(inputs, outputs, test_size=0.25, random_state=5, stratify=outputs)\n",
    "    print(\"Training set has {} samples.\".format(x_train.shape[0]))\n",
    "    print(\"Testing set has {} samples.\".format(x_test.shape[0]))\n",
    "    \n",
    "#     X_train, X_test, Y_train, Y_test = sklearn.model_selection.train_test_split(X, Y, test_size=0.2, random_state=5, stratify=Y)\n",
    "    # Make sure that data still is balanced\n",
    "    print('\\n--- Class balance ---')\n",
    "    print(np.unique(y_train, return_counts=True))\n",
    "    print(np.unique(y_test, return_counts=True))\n",
    "    # Train and evaluate\n",
    "    train_and_evaluate(x_train, y_train, x_test, y_test)\n",
    "    # Plot classifier\n",
    "#     plot_classifier(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 71932 samples.\n",
      "Testing set has 23978 samples.\n",
      "\n",
      "--- Class balance ---\n",
      "(array([0, 1], dtype=int64), array([29997, 41935], dtype=int64))\n",
      "(array([0, 1], dtype=int64), array([ 9999, 13979], dtype=int64))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akash Selvakumar\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Training data --\n",
      "Accuracy: 84.96\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.82     29997\n",
      "           1       0.86      0.88      0.87     41935\n",
      "\n",
      "    accuracy                           0.85     71932\n",
      "   macro avg       0.85      0.84      0.84     71932\n",
      "weighted avg       0.85      0.85      0.85     71932\n",
      "\n",
      "Confusion Matrix:\n",
      "[[24046  5951]\n",
      " [ 4869 37066]]\n",
      "\n",
      "\n",
      "---- Test data ----\n",
      "Accuracy: 84.94\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      9999\n",
      "           1       0.86      0.88      0.87     13979\n",
      "\n",
      "    accuracy                           0.85     23978\n",
      "   macro avg       0.85      0.84      0.84     23978\n",
      "weighted avg       0.85      0.85      0.85     23978\n",
      "\n",
      "Confusion Matrix:\n"
     ]
    },
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-365c5141ef0c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-71-1d2a17228709>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m# Train and evaluate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mtrain_and_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;31m# Plot classifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m#     plot_classifier(inputs, outputs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-69-ace3279eb1e6>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(X_train, Y_train, X_test, Y_test)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Confusion Matrix:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;31m#     print(sklearn.metrics.confusion_matrix(Y_test, predictions))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-68-3425cd3cc553>\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_test, predictions)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mcm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m# sns.heatmap(cm,annot=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# print(cm)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "... last 1 frames repeated, from the frame below ...\n",
      "\u001b[1;32m<ipython-input-68-3425cd3cc553>\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_test, predictions)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mcm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m# sns.heatmap(cm,annot=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# print(cm)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRecursionError\u001b[0m: maximum recursion depth exceeded"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\": main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
